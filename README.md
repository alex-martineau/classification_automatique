# ğŸ¤– Classification automatique des Biens de Consommation

**Classification automatique de produits e-commerce Ã  partir de descriptions textuelles et dâ€™images.**  
Projet de Data Science visant Ã  dÃ©velopper un moteur dâ€™attribution de catÃ©gories capable dâ€™identifier automatiquement le type de produit Ã  partir de ses mÃ©tadonnÃ©es.

---

## ğŸ¯ Objectif du projet

Lâ€™objectif de ce projet est de **concevoir un modÃ¨le de classification multi-modale** (texte + image) permettant de prÃ©dire la catÃ©gorie de produits sur la base :
- des **titres et descriptions textuelles**,  
- et des **images associÃ©es** (dans un second temps).

Ce travail sâ€™inscrit dans une logique dâ€™**industrialisation** dâ€™un moteur de classification automatique utilisable sur un site e-commerce ou un catalogue produit Ã  grande Ã©chelle.

---

## ğŸ§© Contenu du dÃ©pÃ´t

Le dÃ©pÃ´t contient :

- **Notebooks Jupyter** :
  1. `preprocessing_feature_extraction.ipynb`  
     â†’ Nettoyage, normalisation et vectorisation des textes (BoW, TF-IDF, Word2Vec).  
  2. `text_classification_models.ipynb`  
     â†’ Comparaison de modÃ¨les de NLP : TF-IDF, Word2Vec, USE, BERT.  
  3. `image_classification_models.ipynb`  
     â†’ Extraction dâ€™attributs visuels (SIFT, ORB) et classification CNN (VGG16, ResNet50).  

- **Dataset** :  
  `flipkart_com-ecommerce_sample_1050.csv` â€“ extrait de la base *Flipkart e-commerce product sample*.  

- **PrÃ©sentation PowerPoint** :  
  `Martineau_Alexandre_4_presentation_102024.pdf` â€“ synthÃ¨se visuelle du projet et comparaison des performances modÃ¨les.

---

## ğŸ§  MÃ©thodologie

### 1. PrÃ©paration & nettoyage
- VÃ©rification des valeurs manquantes, doublons et anomalies.  
- SÃ©paration du corpus textuel et des mÃ©tadonnÃ©es.  
- Normalisation linguistique : suppression de la ponctuation, *lemmatisation*, *stopwords*, *lowercase*.  

### 2. Feature Engineering
- **Texte** :
  - Bag of Words (baseline)
  - TF-IDF (pondÃ©ration contextuelle)
  - Word2Vec (GoogleNews-300)
  - Universal Sentence Encoder (USE)
  - BERT (Hugging Face / TensorFlow)
- **Image** :
  - Descripteurs SIFT / ORB
  - CNN prÃ©-entraÃ®nÃ©s : *VGG16*, *ResNet50*

### 3. ModÃ©lisation
- **Classifieurs testÃ©s** :
  - Logistic Regression
  - Random Forest
  - Gradient Boosting
  - SVM linÃ©aire et radial
  - RÃ©seaux de neurones profonds (Dense / CNN)
- **Ã‰valuation** :
  - Accuracy, Precision, Recall, F1-score  
  - Confusion matrix, classification report  
  - ARI (*Adjusted Rand Index*) et courbes ROC

---

## ğŸ“Š RÃ©sultats principaux

| ModÃ¨le | Type | Accuracy | ARI | Commentaire |
|---------|------|-----------|-----|--------------|
| Bag of Words | Texte | **0.93** | 0.58 | Baseline robuste |
| TF-IDF | Texte | **0.95** | 0.62 | Meilleur compromis performance / coÃ»t |
| Word2Vec | Texte | 0.72 | 0.30 | Pertinent pour corpus long |
| USE | Texte | 0.89 | 0.50 | Bon contexte sÃ©mantique |
| BERT (Hugging Face) | Texte | **0.93** | 0.60 | Excellente comprÃ©hension contextuelle |
| CNN (VGG16 / ResNet50) | Image | 0.85 | - | Classification visuelle efficace |

> ğŸ† **Meilleure performance globale** : TF-IDF + Gradient Boosting (95 % accuracy)  
> BERT offre cependant une meilleure comprÃ©hension linguistique pour de futures extensions.

---

## ğŸ’¡ Insights clÃ©s

- Le **texte** contient une forte capacitÃ© discriminante â†’ les descriptions produits suffisent Ã  atteindre >90 % de prÃ©cision.  
- Les **images** complÃ¨tent utilement la catÃ©gorisation mais nÃ©cessitent davantage de ressources GPU.  
- Le **modÃ¨le BERT** est le plus prometteur pour un usage en production NLP (API de classification automatisÃ©e).  

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Langage** : Python 3.11  
- **Librairies principales** :  
  `pandas`, `numpy`, `scikit-learn`, `tensorflow`, `transformers`, `nltk`, `gensim`, `opencv`, `matplotlib`, `seaborn`
- **Outils NLP** : TF-IDF, Word2Vec, USE, BERT  
- **Vision par ordinateur** : SIFT, ORB, CNN (VGG16, ResNet50)  
- **Ã‰valuation & Visualisation** : confusion matrix, t-SNE, PCA, heatmaps

---

## ğŸ“‚ Structure du dÃ©pÃ´t

```text
classification_automatique
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ flipkart_com-ecommerce_sample_1050.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ preprocessing_feature_extraction.ipynb
â”‚   â”œâ”€â”€ text_classification_models.ipynb
â”‚   â”œâ”€â”€ image_classification_models.ipynb
â”‚
â”œâ”€â”€ Martineau_Alexandre_4_presentation_102024.pdf
â””â”€â”€ README.md
```

---

## ğŸš€ Perspectives dâ€™amÃ©lioration

- IntÃ©gration dâ€™une API Flask/FastAPI pour la classification en temps rÃ©el.
- Fusion texte + image dans un modÃ¨le multimodal (BERT + CNN).
- Optimisation des embeddings via fine-tuning.
- ImplÃ©mentation dâ€™un systÃ¨me de catÃ©gorisation hiÃ©rarchique (sous-catÃ©gories).

---

## ğŸ§© Conclusion
Ce projet dÃ©montre la faisabilitÃ© dâ€™un systÃ¨me de classification automatique multi-modale performant sur des donnÃ©es e-commerce rÃ©elles.
Les rÃ©sultats confirment la pertinence dâ€™une approche hybride combinant NLP (BERT/TF-IDF) et vision (CNN) pour automatiser la catÃ©gorisation produit Ã  grande Ã©chelle.
